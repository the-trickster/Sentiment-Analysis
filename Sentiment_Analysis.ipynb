{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing required libraries\nimport pandas as pd\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings \nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:24.192187Z","iopub.execute_input":"2021-05-28T11:13:24.192535Z","iopub.status.idle":"2021-05-28T11:13:26.016751Z","shell.execute_reply.started":"2021-05-28T11:13:24.192504Z","shell.execute_reply":"2021-05-28T11:13:26.0156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read the dataset\ndata = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:27.095391Z","iopub.execute_input":"2021-05-28T11:13:27.095749Z","iopub.status.idle":"2021-05-28T11:13:34.857078Z","shell.execute_reply.started":"2021-05-28T11:13:27.095718Z","shell.execute_reply":"2021-05-28T11:13:34.856147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#View the top rows\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:34.858783Z","iopub.execute_input":"2021-05-28T11:13:34.859276Z","iopub.status.idle":"2021-05-28T11:13:34.889797Z","shell.execute_reply.started":"2021-05-28T11:13:34.859239Z","shell.execute_reply":"2021-05-28T11:13:34.888772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#View DataFrame Columns\ndata.columns","metadata":{"execution":{"iopub.status.busy":"2021-05-28T09:03:58.791996Z","iopub.execute_input":"2021-05-28T09:03:58.792463Z","iopub.status.idle":"2021-05-28T09:03:58.798857Z","shell.execute_reply.started":"2021-05-28T09:03:58.792421Z","shell.execute_reply":"2021-05-28T09:03:58.797978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Rename DataFrame Columns\nDATASET_COLUMNS = [\"TARGET\", \"ID\", \"DATE\", \"FLAG\", \"USER\", \"TWEET\"]\ndata.columns = DATASET_COLUMNS\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:35.271345Z","iopub.execute_input":"2021-05-28T11:13:35.271724Z","iopub.status.idle":"2021-05-28T11:13:35.286028Z","shell.execute_reply.started":"2021-05-28T11:13:35.271691Z","shell.execute_reply":"2021-05-28T11:13:35.284898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.DATE = data.DATE.str.replace('2009','2019')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:40.626465Z","iopub.execute_input":"2021-05-28T11:13:40.626819Z","iopub.status.idle":"2021-05-28T11:13:42.276323Z","shell.execute_reply.started":"2021-05-28T11:13:40.626787Z","shell.execute_reply":"2021-05-28T11:13:42.275362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:13:51.113646Z","iopub.execute_input":"2021-05-28T11:13:51.114021Z","iopub.status.idle":"2021-05-28T11:13:51.127025Z","shell.execute_reply.started":"2021-05-28T11:13:51.113988Z","shell.execute_reply":"2021-05-28T11:13:51.12589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.to_csv('Data_Before_Cleaning_Sentiment.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T11:15:44.097977Z","iopub.execute_input":"2021-05-28T11:15:44.09835Z","iopub.status.idle":"2021-05-28T11:15:55.325765Z","shell.execute_reply.started":"2021-05-28T11:15:44.098317Z","shell.execute_reply":"2021-05-28T11:15:55.324582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.595322Z","iopub.execute_input":"2021-05-28T08:55:03.595654Z","iopub.status.idle":"2021-05-28T08:55:03.60859Z","shell.execute_reply.started":"2021-05-28T08:55:03.595624Z","shell.execute_reply":"2021-05-28T08:55:03.607484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.drop('FLAG',axis = 1,inplace = True)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.609998Z","iopub.execute_input":"2021-05-28T08:55:03.610293Z","iopub.status.idle":"2021-05-28T08:55:03.706467Z","shell.execute_reply.started":"2021-05-28T08:55:03.610265Z","shell.execute_reply":"2021-05-28T08:55:03.705672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.707669Z","iopub.execute_input":"2021-05-28T08:55:03.708265Z","iopub.status.idle":"2021-05-28T08:55:03.724139Z","shell.execute_reply.started":"2021-05-28T08:55:03.708221Z","shell.execute_reply":"2021-05-28T08:55:03.722678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.727225Z","iopub.execute_input":"2021-05-28T08:55:03.727632Z","iopub.status.idle":"2021-05-28T08:55:03.737981Z","shell.execute_reply.started":"2021-05-28T08:55:03.727597Z","shell.execute_reply":"2021-05-28T08:55:03.736638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.TARGET.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.741044Z","iopub.execute_input":"2021-05-28T08:55:03.741687Z","iopub.status.idle":"2021-05-28T08:55:03.770143Z","shell.execute_reply.started":"2021-05-28T08:55:03.741644Z","shell.execute_reply":"2021-05-28T08:55:03.76897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positif_data = data[data.TARGET==4].iloc[:40000,:]\nprint(positif_data.shape)\nnegative_data = data[data.TARGET==0].iloc[:20000,:]\nprint(negative_data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.771742Z","iopub.execute_input":"2021-05-28T08:55:03.772361Z","iopub.status.idle":"2021-05-28T08:55:03.921979Z","shell.execute_reply.started":"2021-05-28T08:55:03.772311Z","shell.execute_reply":"2021-05-28T08:55:03.920972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.concat([positif_data,negative_data],axis=0)\ndata.reset_index(drop=True,inplace=True)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.923238Z","iopub.execute_input":"2021-05-28T08:55:03.923595Z","iopub.status.idle":"2021-05-28T08:55:03.944396Z","shell.execute_reply.started":"2021-05-28T08:55:03.92356Z","shell.execute_reply":"2021-05-28T08:55:03.943415Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.TARGET.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.945711Z","iopub.execute_input":"2021-05-28T08:55:03.946002Z","iopub.status.idle":"2021-05-28T08:55:03.954492Z","shell.execute_reply.started":"2021-05-28T08:55:03.945975Z","shell.execute_reply":"2021-05-28T08:55:03.95341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Cleaning\n* The Twitter handles are already masked as @user due to privacy concerns. So, these Twitter handles are hardly giving any information about the nature of the tweet.\n* We can also think of getting rid of the punctuations, numbers and even special characters since they wouldn’t help in differentiating different kinds of tweets.\n* Most of the smaller words do not add much value. For example, ‘pdx’, ‘his’, ‘all’. So, we will try to remove them as well from our data.\n* Once we have executed the above three steps, we can split every tweet into individual words or tokens which is an essential step in any NLP task.\n* In the 4th tweet, there is a word ‘love’. We might also have terms like loves, loving, lovable, etc. in the rest of the data. These terms are often used in the same context. If we can reduce them to their root word, which is ‘love’, then we can reduce the total number of unique words in our data without losing a significant amount of information.","metadata":{}},{"cell_type":"code","source":"#Removing Twitter Handles\ndata['CLEAN_TWEET'] = data.TWEET.str.replace('@','')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:03.955869Z","iopub.execute_input":"2021-05-28T08:55:03.956361Z","iopub.status.idle":"2021-05-28T08:55:04.021502Z","shell.execute_reply.started":"2021-05-28T08:55:03.95619Z","shell.execute_reply":"2021-05-28T08:55:04.020445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing URL Links\ndata['CLEAN_TWEET'] = data['CLEAN_TWEET'].str.replace(r\"http\\S+\", ' ')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:04.022903Z","iopub.execute_input":"2021-05-28T08:55:04.023205Z","iopub.status.idle":"2021-05-28T08:55:04.103723Z","shell.execute_reply.started":"2021-05-28T08:55:04.023174Z","shell.execute_reply":"2021-05-28T08:55:04.102516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing Punctuations and Numbers\ndata['CLEAN_TWEET'] = data['CLEAN_TWEET'].str.replace('[^a-zA-Z]',' ')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:04.104978Z","iopub.execute_input":"2021-05-28T08:55:04.105307Z","iopub.status.idle":"2021-05-28T08:55:04.636451Z","shell.execute_reply.started":"2021-05-28T08:55:04.105276Z","shell.execute_reply":"2021-05-28T08:55:04.63569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Removing Stop Words\nstopwords = nltk.corpus.stopwords.words('english')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:04.63755Z","iopub.execute_input":"2021-05-28T08:55:04.638012Z","iopub.status.idle":"2021-05-28T08:55:04.659683Z","shell.execute_reply.started":"2021-05-28T08:55:04.637965Z","shell.execute_reply":"2021-05-28T08:55:04.658788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.\n\nWe would not want these words to take up space in our database, or taking up valuable processing time. For this, we can remove them easily, by storing a list of words that you consider to stop words. NLTK(Natural Language Toolkit) in python has a list of stopwords stored in 16 different languages.","metadata":{}},{"cell_type":"code","source":"def change(text):\n    clean_text = [item for item in text.split() if item not in stopwords]\n    return ' '.join(clean_text)\n    \ndata['CLEAN_TWEET'] = data['CLEAN_TWEET'].apply(lambda text: change(text.lower()))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:04.66089Z","iopub.execute_input":"2021-05-28T08:55:04.661179Z","iopub.status.idle":"2021-05-28T08:55:06.002074Z","shell.execute_reply.started":"2021-05-28T08:55:04.661152Z","shell.execute_reply":"2021-05-28T08:55:06.000466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization\nTokens are individual terms or words, and tokenization is the process of splitting a string of text into tokens.","metadata":{}},{"cell_type":"code","source":"data['CLEAN_TWEET'] = data['CLEAN_TWEET'].apply(lambda text: text.split())\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:06.003928Z","iopub.execute_input":"2021-05-28T08:55:06.004405Z","iopub.status.idle":"2021-05-28T08:55:06.107512Z","shell.execute_reply.started":"2021-05-28T08:55:06.00434Z","shell.execute_reply":"2021-05-28T08:55:06.106484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stemming\n* Stemming is a rule-based process of stripping the suffixes (“ing”, “ly”, “es”, “s” etc) from a word. \n* For example – “play”, “player”, “played”, “plays” and “playing” are the different variations of the word – “play”.","metadata":{}},{"cell_type":"code","source":"from nltk.stem.porter import * \nstemmer = PorterStemmer() \ndata['CLEAN_TWEET'] = data['CLEAN_TWEET'].apply(lambda text: [stemmer.stem(item) for item in text])\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:06.10901Z","iopub.execute_input":"2021-05-28T08:55:06.109431Z","iopub.status.idle":"2021-05-28T08:55:19.02187Z","shell.execute_reply.started":"2021-05-28T08:55:06.109385Z","shell.execute_reply":"2021-05-28T08:55:19.02082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now let’s stitch these tokens back together.\ndata['CLEAN_TWEET'] = data['CLEAN_TWEET'].apply(lambda text: ' '.join([item for item in text]))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.023218Z","iopub.execute_input":"2021-05-28T08:55:19.023529Z","iopub.status.idle":"2021-05-28T08:55:19.118972Z","shell.execute_reply.started":"2021-05-28T08:55:19.0235Z","shell.execute_reply":"2021-05-28T08:55:19.118195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Now we’ll add columns to the original DataFrame to store polarity_score dictionaries, extracted compound scores, and new “pos/neg” labels derived from the compound score. \n* We’ll use this last column to perform an accuracy test. The reviews in this method will be classified into negative, positive and, neutral ratio.","metadata":{}},{"cell_type":"code","source":"from textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.119951Z","iopub.execute_input":"2021-05-28T08:55:19.120366Z","iopub.status.idle":"2021-05-28T08:55:19.191407Z","shell.execute_reply.started":"2021-05-28T08:55:19.120336Z","shell.execute_reply":"2021-05-28T08:55:19.190435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''#Calculating Negative, Positive, Neutral and Compound values\ndata[['polarity', 'subjectivity']] = data['CLEAN_TWEET'].apply(lambda text: pd.Series(TextBlob(text).sentiment))\n\nfor index, row in data['CLEAN_TWEET'].iteritems():\n    score = SentimentIntensityAnalyzer().polarity_scores(row)\n    neg = score['neg']\n    neu = score['neu']\n    pos = score['pos']\n    comp = score['compound']\n    if neg > pos:\n        data.loc[index, 'sentiment'] = 1 #Negative\n    elif pos > neg:\n        data.loc[index, 'sentiment'] = 1 #Positive\n    else:\n        data.loc[index, 'sentiment'] = 2 #Neutral\n        \n    data.loc[index, 'neg'] = neg\n    data.loc[index, 'neu'] = neu\n    data.loc[index, 'pos'] = pos\n    data.loc[index, 'compound'] = comp\n    \ndata.to_csv('twitter_sentiment.csv',index=False)'''","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.193109Z","iopub.execute_input":"2021-05-28T08:55:19.193576Z","iopub.status.idle":"2021-05-28T08:55:19.200458Z","shell.execute_reply.started":"2021-05-28T08:55:19.19353Z","shell.execute_reply":"2021-05-28T08:55:19.199659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('../input/handson/twitter_sentiment.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.204695Z","iopub.execute_input":"2021-05-28T08:55:19.205035Z","iopub.status.idle":"2021-05-28T08:55:19.807805Z","shell.execute_reply.started":"2021-05-28T08:55:19.205003Z","shell.execute_reply":"2021-05-28T08:55:19.806781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['CLEAN_TWEET']=data['CLEAN_TWEET'].fillna('')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.809698Z","iopub.execute_input":"2021-05-28T08:55:19.809997Z","iopub.status.idle":"2021-05-28T08:55:19.824182Z","shell.execute_reply.started":"2021-05-28T08:55:19.809968Z","shell.execute_reply":"2021-05-28T08:55:19.823057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We have to be a little careful here in selecting the length of the words which we want to remove. So, we have decided to remove all the words having length 3 or less. \n* For example, terms like “hmm”, “oh” are of very little use. It is better to get rid of them.","metadata":{}},{"cell_type":"code","source":"data['CLEAN_TWEET'] = data['CLEAN_TWEET'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.825515Z","iopub.execute_input":"2021-05-28T08:55:19.825949Z","iopub.status.idle":"2021-05-28T08:55:19.985742Z","shell.execute_reply.started":"2021-05-28T08:55:19.825859Z","shell.execute_reply":"2021-05-28T08:55:19.984514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sentiment = data.sentiment.astype(int)\ndata.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:19.987304Z","iopub.execute_input":"2021-05-28T08:55:19.987785Z","iopub.status.idle":"2021-05-28T08:55:19.999234Z","shell.execute_reply.started":"2021-05-28T08:55:19.987738Z","shell.execute_reply":"2021-05-28T08:55:19.998051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sentiment.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:20.000552Z","iopub.execute_input":"2021-05-28T08:55:20.000984Z","iopub.status.idle":"2021-05-28T08:55:20.01144Z","shell.execute_reply.started":"2021-05-28T08:55:20.000947Z","shell.execute_reply":"2021-05-28T08:55:20.010471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:20.012933Z","iopub.execute_input":"2021-05-28T08:55:20.013253Z","iopub.status.idle":"2021-05-28T08:55:20.060018Z","shell.execute_reply.started":"2021-05-28T08:55:20.013214Z","shell.execute_reply":"2021-05-28T08:55:20.05913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Word Cloud is a data visualization technique used for representing text data in which the size of each word indicates its frequency or importance. Significant textual data points can be highlighted using a word cloud. Word clouds are widely used for analyzing data from social network websites.","metadata":{}},{"cell_type":"code","source":"positive_words = ' '.join([text for text in data.CLEAN_TWEET[data.sentiment==1]])\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(positive_words) \n\nplt.figure(figsize=(10, 7))\nplt.imshow(wordcloud, interpolation=\"bilinear\");","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:20.061322Z","iopub.execute_input":"2021-05-28T08:55:20.061853Z","iopub.status.idle":"2021-05-28T08:55:23.32821Z","shell.execute_reply.started":"2021-05-28T08:55:20.06182Z","shell.execute_reply":"2021-05-28T08:55:23.326591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:23.330125Z","iopub.execute_input":"2021-05-28T08:55:23.330612Z","iopub.status.idle":"2021-05-28T08:55:24.71097Z","shell.execute_reply.started":"2021-05-28T08:55:23.330564Z","shell.execute_reply":"2021-05-28T08:55:24.709751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for item in positive_words.split()])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n\nfig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Positive Words')\nfig","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:24.712351Z","iopub.execute_input":"2021-05-28T08:55:24.712805Z","iopub.status.idle":"2021-05-28T08:55:26.099732Z","shell.execute_reply.started":"2021-05-28T08:55:24.712767Z","shell.execute_reply":"2021-05-28T08:55:26.098667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"negative_words = ' '.join([text for text in data.CLEAN_TWEET[data.sentiment==0]])\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(negative_words) \n\nplt.figure(figsize=(10, 7)) \nplt.imshow(wordcloud, interpolation=\"bilinear\");","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:26.101033Z","iopub.execute_input":"2021-05-28T08:55:26.101352Z","iopub.status.idle":"2021-05-28T08:55:27.954536Z","shell.execute_reply.started":"2021-05-28T08:55:26.10132Z","shell.execute_reply":"2021-05-28T08:55:27.953488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for item in negative_words.split()])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n\nfig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Negative Words')\nfig","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:27.955963Z","iopub.execute_input":"2021-05-28T08:55:27.956244Z","iopub.status.idle":"2021-05-28T08:55:28.050694Z","shell.execute_reply.started":"2021-05-28T08:55:27.956217Z","shell.execute_reply":"2021-05-28T08:55:28.049668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"neutral_words = ' '.join([text for text in data.CLEAN_TWEET[data.sentiment==2]])\nwordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(neutral_words) \n\nplt.figure(figsize=(10, 7)) \nplt.imshow(wordcloud, interpolation=\"bilinear\");","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:28.052064Z","iopub.execute_input":"2021-05-28T08:55:28.052366Z","iopub.status.idle":"2021-05-28T08:55:30.292499Z","shell.execute_reply.started":"2021-05-28T08:55:28.052337Z","shell.execute_reply":"2021-05-28T08:55:30.29167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top = Counter([item for item in neutral_words.split()])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:30.293773Z","iopub.execute_input":"2021-05-28T08:55:30.294073Z","iopub.status.idle":"2021-05-28T08:55:30.342763Z","shell.execute_reply.started":"2021-05-28T08:55:30.294043Z","shell.execute_reply":"2021-05-28T08:55:30.341568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Neutral Words')\nfig","metadata":{"execution":{"iopub.status.busy":"2021-05-28T09:00:14.502029Z","iopub.execute_input":"2021-05-28T09:00:14.502454Z","iopub.status.idle":"2021-05-28T09:00:14.58549Z","shell.execute_reply.started":"2021-05-28T09:00:14.502419Z","shell.execute_reply":"2021-05-28T09:00:14.584535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(x='sentiment',data=data);","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:30.422858Z","iopub.execute_input":"2021-05-28T08:55:30.423142Z","iopub.status.idle":"2021-05-28T08:55:30.550039Z","shell.execute_reply.started":"2021-05-28T08:55:30.423115Z","shell.execute_reply":"2021-05-28T08:55:30.549342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NLP Classification Task","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix,classification_report","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:30.551336Z","iopub.execute_input":"2021-05-28T08:55:30.551891Z","iopub.status.idle":"2021-05-28T08:55:30.702316Z","shell.execute_reply.started":"2021-05-28T08:55:30.551857Z","shell.execute_reply":"2021-05-28T08:55:30.701495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Bag of words is a commonly used model in Natural Language Processing. \n* The idea behind this model is the creation of vocabulary that contains the collection of different words, and each word is associated with a count of how it occurs. \n* Later, the vocabulary is used to create d-dimensional feature vectors.","metadata":{}},{"cell_type":"code","source":"x = data.CLEAN_TWEET\ny = data.sentiment","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:30.703668Z","iopub.execute_input":"2021-05-28T08:55:30.704211Z","iopub.status.idle":"2021-05-28T08:55:30.709001Z","shell.execute_reply.started":"2021-05-28T08:55:30.704174Z","shell.execute_reply":"2021-05-28T08:55:30.707991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* CountVectorizer is a great tool provided by the scikit-learn library in Python. It is used to transform a given text into a vector on the basis of the frequency (count) of each word that occurs in the entire text. This is helpful when we have multiple such texts, and we wish to convert each word in each text into vectors.\n* CountVectorizer creates a matrix in which each unique word is represented by a column of the matrix, and each text sample from the document is a row in the matrix. The value of each cell is nothing but the count of the word in that particular text sample. ","metadata":{}},{"cell_type":"code","source":"count_vectorizer = CountVectorizer() \ncv = count_vectorizer.fit_transform(x)\ncv.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:30.710662Z","iopub.execute_input":"2021-05-28T08:55:30.711043Z","iopub.status.idle":"2021-05-28T08:55:31.528888Z","shell.execute_reply.started":"2021-05-28T08:55:30.711008Z","shell.execute_reply":"2021-05-28T08:55:31.527946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Train Dataset: We use datasets to train the model using various machine learning algorithms. Training a model is required so that it can understand the various patterns, rules, and, features.\n* Test Dataset: Once our machine learning model has been trained on a given dataset, then we test the model. In this step, we check for the accuracy of our model by providing a test dataset to it.","metadata":{}},{"cell_type":"code","source":"#Let's split our data into training and testing data.\nxtrain,xtest,ytrain,ytest = train_test_split(cv, y,test_size=0.2,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.530121Z","iopub.execute_input":"2021-05-28T08:55:31.530442Z","iopub.status.idle":"2021-05-28T08:55:31.548051Z","shell.execute_reply.started":"2021-05-28T08:55:31.530409Z","shell.execute_reply":"2021-05-28T08:55:31.546907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training a Model","metadata":{}},{"cell_type":"markdown","source":"* Naive Bayes is based on Bayes’ theorem, where the adjective Naïve says that features in the dataset are mutually independent. \n* Occurrence of one feature does not affect the probability of occurrence of the other feature. \n* For small sample sizes, Naïve Bayes can outperform the most powerful alternatives. \n* Being relatively robust, easy to implement, fast, and accurate, it is used in many different fields.","metadata":{}},{"cell_type":"code","source":"nb = MultinomialNB()","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.549545Z","iopub.execute_input":"2021-05-28T08:55:31.550169Z","iopub.status.idle":"2021-05-28T08:55:31.554771Z","shell.execute_reply.started":"2021-05-28T08:55:31.550121Z","shell.execute_reply":"2021-05-28T08:55:31.553773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb.fit(xtrain,ytrain)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.556104Z","iopub.execute_input":"2021-05-28T08:55:31.55642Z","iopub.status.idle":"2021-05-28T08:55:31.592Z","shell.execute_reply.started":"2021-05-28T08:55:31.556367Z","shell.execute_reply":"2021-05-28T08:55:31.591064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions and Evaluations","metadata":{}},{"cell_type":"code","source":"predictions = nb.predict(xtest)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.593138Z","iopub.execute_input":"2021-05-28T08:55:31.593436Z","iopub.status.idle":"2021-05-28T08:55:31.600846Z","shell.execute_reply.started":"2021-05-28T08:55:31.593406Z","shell.execute_reply":"2021-05-28T08:55:31.599667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. \n\nLet's now define the most basic terms:\n* true positives (TP): These are cases in which we predicted yes (they have the disease), and they do have the disease.\n* true negatives (TN): We predicted no, and they don't have the disease.\n* false positives (FP): We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n* false negatives (FN): We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")","metadata":{}},{"cell_type":"code","source":"print(confusion_matrix(ytest,predictions))\nprint('\\n')\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.602706Z","iopub.execute_input":"2021-05-28T08:55:31.603325Z","iopub.status.idle":"2021-05-28T08:55:31.65124Z","shell.execute_reply.started":"2021-05-28T08:55:31.603275Z","shell.execute_reply":"2021-05-28T08:55:31.65022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(accuracy_score(predictions,ytest))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.653009Z","iopub.execute_input":"2021-05-28T08:55:31.653436Z","iopub.status.idle":"2021-05-28T08:55:31.660093Z","shell.execute_reply.started":"2021-05-28T08:55:31.653393Z","shell.execute_reply":"2021-05-28T08:55:31.659135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* The Random forest is a supervised Machine learning algorithm used for classification, regression, and other tasks using decision trees.\n* The Random forest classifier creates a set of decision trees from a randomly selected subset of the training set. \n* It is basically a set of decision trees (DT) from a randomly selected subset of the training set and then It collects the votes from different decision trees to decide the final prediction.","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=10, random_state=42)\nrf.fit(xtrain,ytrain)\npredictions = rf.predict(xtest)\nprint(accuracy_score(predictions,ytest))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:55:31.661488Z","iopub.execute_input":"2021-05-28T08:55:31.661789Z","iopub.status.idle":"2021-05-28T08:56:09.813663Z","shell.execute_reply.started":"2021-05-28T08:55:31.66176Z","shell.execute_reply":"2021-05-28T08:56:09.812615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Pipelines are used for splitting up your machine learning workflows into independent, reusable, modular parts that can then be pipelined together to continuously improve the accuracy of the model and achieve a successful algorithm.\n\nPipeline will include the following steps:\n1. Preprocessing Text and Building Vocabulary: Removing unwanted texts (stop words), punctuations, URLs, handles, etc. which do not have any sentimental value. And then adding unique preprocessed words to a vocabulary.\n2. Feature Extraction: Iterating through each data example to extract features using a frequency dictionary and finally create a feature matrix.\n3. Training Model: We’ll then use our feature matrix to train a Logistic Regression model in order to use that model for predicting sentiments.\n4. Testing Model: Using our trained model to get the predictions from data it never saw.","metadata":{}},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:09.815042Z","iopub.execute_input":"2021-05-28T08:56:09.81532Z","iopub.status.idle":"2021-05-28T08:56:09.821387Z","shell.execute_reply.started":"2021-05-28T08:56:09.815293Z","shell.execute_reply":"2021-05-28T08:56:09.820452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('bow', CountVectorizer()),  # strings to token integer counts\n    ('classifier', MultinomialNB()),  # train on Naive Bayes classifier\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:09.822666Z","iopub.execute_input":"2021-05-28T08:56:09.822945Z","iopub.status.idle":"2021-05-28T08:56:09.832817Z","shell.execute_reply.started":"2021-05-28T08:56:09.82292Z","shell.execute_reply":"2021-05-28T08:56:09.831577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = data.CLEAN_TWEET\ny = data.sentiment\nxtrain,xtest,ytrain,ytest = train_test_split(x, y,test_size=0.3,random_state=62)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:09.834069Z","iopub.execute_input":"2021-05-28T08:56:09.834367Z","iopub.status.idle":"2021-05-28T08:56:09.854551Z","shell.execute_reply.started":"2021-05-28T08:56:09.83434Z","shell.execute_reply":"2021-05-28T08:56:09.853386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline.fit(xtrain,ytrain)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:09.855806Z","iopub.execute_input":"2021-05-28T08:56:09.856104Z","iopub.status.idle":"2021-05-28T08:56:10.459869Z","shell.execute_reply.started":"2021-05-28T08:56:09.856076Z","shell.execute_reply":"2021-05-28T08:56:10.45884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. \n* More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as shown below.","metadata":{}},{"cell_type":"code","source":"predictions = pipeline.predict(xtest)\nprint(confusion_matrix(ytest,predictions))\nprint(classification_report(ytest,predictions))","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:10.461345Z","iopub.execute_input":"2021-05-28T08:56:10.461945Z","iopub.status.idle":"2021-05-28T08:56:10.726566Z","shell.execute_reply.started":"2021-05-28T08:56:10.4619Z","shell.execute_reply":"2021-05-28T08:56:10.725501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Pickle is the standard way of serializing objects in Python.\n* You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file.\n* Later you can load this file to deserialize your model and use it to make new predictions.","metadata":{}},{"cell_type":"code","source":"import joblib\nDump the pipeline model\njoblib.dump(pipeline,'Sentiment')","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:10.727971Z","iopub.execute_input":"2021-05-28T08:56:10.728557Z","iopub.status.idle":"2021-05-28T08:56:10.732851Z","shell.execute_reply.started":"2021-05-28T08:56:10.728512Z","shell.execute_reply":"2021-05-28T08:56:10.731735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Test the pipeline with a sample tweet\npipeline.predict(['killer'])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:56:10.734056Z","iopub.execute_input":"2021-05-28T08:56:10.734323Z","iopub.status.idle":"2021-05-28T08:56:10.748963Z","shell.execute_reply.started":"2021-05-28T08:56:10.734296Z","shell.execute_reply":"2021-05-28T08:56:10.74777Z"},"trusted":true},"execution_count":null,"outputs":[]}]}